{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the HF_HOME directory if needed. What is below is obviously hard-coded for Arjun's account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/work/arjunguha-research-group/arjun/cache/hf_home\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable retina mode for high-resolution plots\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "from typing import Optional, Union\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHIVE_PATH = \"/work/arjunguha-research-group/projects/prompt_trajectories/causal_intervention\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Results after Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gunzip_json(path: Union[Path, str]) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Reads a .json.gz file, but produces None if any error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with gzip.open(path, \"rt\") as f:\n",
    "            data = json.load(f)\n",
    "            return data\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "def compute_pass1(results_data, completions_data):\n",
    "    total_count = 0\n",
    "    total_successes = 0\n",
    "    for (completion, result) in zip(completions_data[\"completions\"], results_data[\"results\"]):\n",
    "        this_count = completion[\"count\"]\n",
    "        this_successes = this_count if result[\"status\"] == \"OK\" else 0\n",
    "        total_count += this_count\n",
    "        total_successes += this_successes\n",
    "    return {\n",
    "        \"n_successes\": total_successes,\n",
    "        \"n_completions\": total_count,\n",
    "        \"pass1\": total_successes / total_count\n",
    "    }\n",
    "\n",
    "def process_multiple_result_file(p: Union[Path, str], extras: dict): \n",
    "    data = gunzip_json(p)\n",
    "    completions_data = gunzip_json(p.parent / p.name.replace(\".results.json.gz\", \".json.gz\"))\n",
    "\n",
    "    assert \"prompt\" not in extras\n",
    "    assert \"problem\" not in extras\n",
    "    assert \"studenteval_id\" not in extras\n",
    "    assert \"pass1\" not in extras\n",
    "    return {\n",
    "        \"prompt\": data[\"prompt\"],\n",
    "        \"problem\": data[\"problem\"],\n",
    "        \"studenteval_id\": data[\"__index_level_0__\"],\n",
    "        \"path\": str(p),\n",
    "        **compute_pass1(data,completions_data),\n",
    "        **extras\n",
    "    }\n",
    "\n",
    "def process_multiple_dir(p: Union[Path, str], extras: dict):\n",
    "    if type(p) == str:\n",
    "        p = Path(p)\n",
    "    \n",
    "    items = [ ]\n",
    "    for results_json in p.glob(\"*\"):\n",
    "        if not results_json.name.endswith(\".results.json.gz\"):\n",
    "            continue\n",
    "        items.append(process_multiple_result_file(results_json, extras))\n",
    "    return items\n",
    "    \n",
    "def process_single_intervention_dir(p: Union[Path, str], extras: dict):\n",
    "    assert \"intervention_category\" not in extras\n",
    "    assert \"intervention\" not in extras\n",
    "\n",
    "    if type(p) == str:\n",
    "        p = Path(p)\n",
    "\n",
    "    # Example of dir_name: generations_all.prompts.full.label.d2c1570_typecast.convert\n",
    "    dir_name = p.name\n",
    "    git_hash_and_intervention_category = dir_name.split(\".\")[-2]\n",
    "    intervention_category = git_hash_and_intervention_category.split(\"_\", maxsplit=1)[1]\n",
    "    intervention = dir_name.split(\".\")[-1]\n",
    "    more_extras = {\n",
    "        \"intervention_category\": intervention_category,\n",
    "        \"intervention\": intervention,\n",
    "        **extras\n",
    "    }\n",
    "\n",
    "    return process_multiple_dir(p / \"extracted_jsons\", more_extras)\n",
    "\n",
    "def process_all_interventions_dir(p: Union[Path, str], extras: dict):\n",
    "    if type(p) == str:\n",
    "        p = Path(p)\n",
    "\n",
    "    items = [ ]\n",
    "    for d in p.glob(\"*\"):\n",
    "        if \"studenteval\" in d.name:\n",
    "            # Not the best directory organization. This is shade at Arya.\n",
    "            continue\n",
    "        if not d.is_dir():\n",
    "            # Won't happen, right?\n",
    "            continue\n",
    "        items.extend(process_single_intervention_dir(d, extras))\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below takes up to 5 minutes to run on Discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_interventions(model_name: str):\n",
    "    base_df = pd.DataFrame(\n",
    "        process_multiple_dir(\n",
    "            f\"{ARCHIVE_PATH}/{model_name}/studenteval/extracted_jsons\", \n",
    "            { \"model\": model_name } \n",
    "        )\n",
    "    )\n",
    "    df = pd.DataFrame(process_all_interventions_dir(\n",
    "        f\"{ARCHIVE_PATH}/{model_name}/interventions\",\n",
    "        { \"model\": model_name }\n",
    "    ))\n",
    "    base_merged_df = pd.merge(df, base_df, on=\"studenteval_id\")\n",
    "    assert len(df) == len(base_merged_df)\n",
    "    return base_merged_df\n",
    "\n",
    "llama3p1_8b_base_df = load_all_interventions(\"llama3p1_8b_base\")\n",
    "llama3p1_70b_base_df = load_all_interventions(\"llama3p1_70b_base\")\n",
    "\n",
    "assert len(llama3p1_8b_base_df) == len(llama3p1_70b_base_df)\n",
    "assert len(llama3p1_8b_base_df) == 13456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4o_mini_df = load_all_interventions(\"gpt4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-hoc Determine Original Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`WORDS_V` below is copied from another file. Loading it loads Spacey, which is\n",
    "very annoying. We should actually move WORDS_V to a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS_V = {\n",
    "    \"word\":[\"word\",\"words\"],\n",
    "    \"phrase\":[\"phrase\",\"phrases\"],\n",
    "    \"string\":[\"string\",\"strings\"],\n",
    "    \"character\":[\"character\",\"characters\"],\n",
    "    \"set of characters\":[\"set of characters\",\"sets of characters\"],\n",
    "    \"brackets\":[\"brackets\"],\n",
    "    \"set of brackets\":[\"set of brackets\",\"sets of brackets\"],\n",
    "    \"set\":[\"set\",\"sets\"],\n",
    "    \"list\":[\"list\",\"lists\"],\n",
    "    \"array\":[\"array\",\"arrays\"],\n",
    "    \"array list\":[\"array list\",\"array lists\"],\n",
    "    \"map\":[\"map\",\"maps\"],\n",
    "    \"dictionary\":[\"dictionary\",\"dictionaries\"],\n",
    "    \"integer\":[\"integer\",\"integers\"],\n",
    "    \"whole number\":[\"whole number\",\"whole numbers\"],\n",
    "    \"int\":[\"int\",\"ints\"],\n",
    "    \"output\":[\"output\",\"outputs\",\"outputted\",\"outputting\"],\n",
    "    \"return\":[\"return\",\"returns\",\"returned\",\"returning\"],\n",
    "    \"print\":[\"print\",\"prints\",\"printed\",\"printing\"],\n",
    "    \"produce\":[\"produce\",\"produces\",\"produced\",\"producing\"],\n",
    "    \"display\":[\"display\",\"displays\",\"displayed\",\"displaying\"],\n",
    "    \"parameter\":[\"parameter\",\"parameters\"],\n",
    "    \"argument\":[\"argument\",\"arguments\"],\n",
    "    \"value provided\":[\"value provided\",\"values provided\"],\n",
    "    \"input\":[\"input\",\"inputs\",\"inputted\"],\n",
    "    \"take\":[\"take\",\"takes\"],\n",
    "    \"bring in\":[\"bring in\",\"brings in\"],\n",
    "    \"accept\":[\"accept\",\"accepts\"],\n",
    "    \"get\":[\"get\",\"gets\"],\n",
    "    \"provide\":[\"provide\",\"provides\",\"provided\"],\n",
    "    \"enter\":[\"enter\",\"enters\",\"entered\"],\n",
    "    \"combine\":[\"combine\",\"combines\",\"combined\",\"combining\"],\n",
    "    \"splice\":[\"splice\",\"splices\",\"spliced\",\"splicing\"],\n",
    "    \"concatenate\":[\"concatenate\",\"concatenates\",\"concatenated\",\"concatenating\"],\n",
    "    \"add\":[\"add\",\"adds\",\"added\",\"adding\"],\n",
    "    \"insert\":[\"insert\",\"inserts\",\"inserted\",\"inserting\"],\n",
    "    \"attach\":[\"attach\",\"attaches\",\"attached\",\"attaching\"],\n",
    "    \"append\":[\"append\",\"appends\",\"appended\",\"appending\"],\n",
    "    \"go through\":[\"go through\",\"goes through\"],\n",
    "    \"run through\":[\"run through\",\"runs through\"],\n",
    "    \"iterate through\":[\"iterate through\",\"iterates through\"],\n",
    "    \"loop through\":[\"loop through\",\"loops through\"],\n",
    "    \"run a for loop through\":[\"run a for loop through\",\"runs a for loop through\"],\n",
    "    \"look through\":[\"look through\",\"looks through\"],\n",
    "    \"execute a for loop with\":[\"execute a for loop with\",\"executes a for loop with\"],\n",
    "    \"skip\":[\"skip\",\"skips\",\"skipped\",\"skipping\"],\n",
    "    \"avoid\":[\"avoid\",\"avoids\",\"avoided\",\"avoiding\"],\n",
    "    \"neglect\":[\"neglect\",\"neglects\",\"neglected\",\"neglecting\"],\n",
    "    \"ignore\":[\"ignore\",\"ignores\",\"ignored\",\"ignoring\"],\n",
    "    \"remove\":[\"remove\",\"removes\",\"removed\",\"removing\"],\n",
    "    \"convert\":[\"convert\",\"converts\",\"converted\",\"converting\"],\n",
    "    \"change\":[\"change\",\"changes\",\"changed\",\"changing\"],\n",
    "    \"typecast\":[\"typecast\",\"typecasts\",\"typecasted\",\"typecasting\"],\n",
    "    \"type cast\":[\"type cast\",\"type casts\",\"type casted\",\"type casting\"],\n",
    "    \"cast\":[\"cast\",\"casts\",\"casted\",\"casting\"],\n",
    "    \"key\":[\"key\",\"keys\"],\n",
    "    \"item\":[\"item\",\"items\"],\n",
    "    \"entry\":[\"entry\",\"entries\"],\n",
    "    \"attribute\":[\"attribute\",\"attributes\"],\n",
    "    \"part\":[\"part\",\"parts\"],\n",
    "    \"element\":[\"element\",\"elements\"],\n",
    "    \"variable\":[\"variable\",\"variables\"],\n",
    "}\n",
    "\n",
    "def process_jsonl_with_original(p: Union[Path, str]):\n",
    "    if type(p) == str:\n",
    "        p = Path(p)\n",
    "\n",
    "    # Example of dir_name: generations_all.prompts.full.label.d2c1570_concatenate.add.jsonl\n",
    "    # where \"add\" is subst intervention\n",
    "    dir_name = p.name\n",
    "    git_hash_and_rest = dir_name.split(\".\")[-3]\n",
    "    git_hash, intervention_category = git_hash_and_rest.split(\"_\", maxsplit=1)\n",
    "    intervention = dir_name.split(\".\")[-2]\n",
    "    jsonl = pd.read_json(p, lines=True)\n",
    "    jsonl[\"intervention_category\"] = intervention_category\n",
    "    jsonl[\"intervention\"] = intervention\n",
    "    jsonl[\"studenteval_id\"] = jsonl[\"__index_level_0__\"]\n",
    "    return jsonl[[\"original\", \"intervention_category\", \"intervention\", \"studenteval_id\"]]\n",
    "\n",
    "MISSING_TERMS = set()\n",
    "def get_original(item):\n",
    "    # Find original_tags_df.original in values (a list) of CATEGORIES_V. Use the key for that category as the new value.\n",
    "    item = str(item[\"original\"].lower())\n",
    "    for k, v in WORDS_V.items():\n",
    "        if item in v:\n",
    "            return k.replace(\" \", \"_\")\n",
    "    return item\n",
    "    \n",
    "original_word_dfs = [ ]\n",
    "for p in (Path(ARCHIVE_PATH) / \"intervention_prompts\").glob(\"*.jsonl\"):\n",
    "    original_word_dfs.append(process_jsonl_with_original(p))\n",
    "original_words_df = pd.concat(original_word_dfs)\n",
    "original_words_df[\"original_word\"] = original_words_df.apply(get_original, axis=1)\n",
    "assert len(original_words_df) == len(llama3p1_8b_base_df)\n",
    "original_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_words_df.intervention_category.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Intervened Prompt with Original Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_original_words(df):\n",
    "    merged_df = pd.merge(df, original_words_df, on=[\"studenteval_id\", \"intervention_category\", \"intervention\"])\n",
    "    merged_df[\"pass1_diff\"] = merged_df.pass1_x - merged_df.pass1_y\n",
    "    assert len(merged_df) == len(df)\n",
    "    return merged_df\n",
    "\n",
    "llama3p1_8b_with_originals_df = add_original_words(llama3p1_8b_base_df)\n",
    "llama3p1_70_with_originals_df = add_original_words(llama3p1_70b_base_df)\n",
    "gpt4o_mini_with_originals_df = add_original_words(gpt4o_mini_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Rare Expressions into an Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rare_expressions(df):\n",
    "    # Group by original_word and intervention_category\n",
    "    def grouper(x):\n",
    "        return len(x) < 3\n",
    "    grouped_df = df.groupby(['original_word', 'intervention']).filter(grouper)\n",
    "\n",
    "    # Create an updated version of merged_df where the original_word for all of\n",
    "    # the rows selected above is set to \"other\"\n",
    "    simplified_df = df.copy()\n",
    "    simplified_df.loc[grouped_df.index, 'original_word'] = 'other'\n",
    "    return simplified_df\n",
    "\n",
    "llama3p1_8b_with_others_df = combine_rare_expressions(llama3p1_8b_with_originals_df)\n",
    "llama3p1_70b_with_others_df = combine_rare_expressions(llama3p1_70_with_originals_df)\n",
    "gpt4o_mini_with_others_df = combine_rare_expressions(gpt4o_mini_with_originals_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family='serif')\n",
    "\n",
    "\n",
    "def plot_heatmap(df, intervention_categories, output_path, nrows=3, ncols=2, figsize=(8.5, 11)):\n",
    "    global axes\n",
    "    assert len(intervention_categories) <= 6\n",
    "    # Create a figure with subplots for each intervention category\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    \n",
    "    axes = axes.flatten()  # Flatten the 2D array of axes for easier indexing\n",
    "\n",
    "    # Determine the range of values for the heatmaps\n",
    "    category_means = df.groupby(['original_word', 'intervention'])[\"pass1_diff\"].mean()\n",
    "    vmin = category_means.min()\n",
    "    vmax = category_means.max()\n",
    "\n",
    "    for idx, category in enumerate(intervention_categories):\n",
    "        category_df = df[df.intervention_category == category].copy()\n",
    "        category_df['intervention'] = category_df['intervention'].str.replace('_', ' ')\n",
    "        category_df['original_word'] = category_df['original_word'].str.replace('_', ' ')\n",
    "\n",
    "        # Pivot the dataframe to create matrices for mean and count\n",
    "        heatmap_data_mean = category_df.pivot_table(values='pass1_diff', \n",
    "                                                    index='intervention', \n",
    "                                                    columns='original_word', \n",
    "                                                    aggfunc='mean')\n",
    "        heatmap_data_count = category_df.pivot_table(values='pass1_diff', \n",
    "                                                    index='intervention', \n",
    "                                                    columns='original_word', \n",
    "                                                    aggfunc='count')\n",
    "        \n",
    "        # Combine mean and count into a single string for each cell\n",
    "        heatmap_data_combined = heatmap_data_mean.applymap(lambda x: f'{x:.2f}')\n",
    "\n",
    "        # Create the heatmap on the corresponding subplot\n",
    "        sns.heatmap(heatmap_data_mean, annot=heatmap_data_combined, fmt='', \n",
    "                    cmap='coolwarm', center=0, ax=axes[idx], \n",
    "                    vmin=vmin, vmax=vmax)\n",
    "        axes[idx].tick_params(axis='x', rotation=45, labelsize=6)\n",
    "        axes[idx].tick_params(axis='y', rotation=45, labelsize=6)\n",
    "        if idx >= len(intervention_categories) - 2:\n",
    "            axes[idx].set_xlabel(\"Expression\")\n",
    "        else:\n",
    "            axes[idx].set_xlabel(\"\")\n",
    "        if idx % 2 == 0:\n",
    "            axes[idx].set_ylabel(\"Intervention\")\n",
    "        else:\n",
    "            axes[idx].set_ylabel(\"\")\n",
    "\n",
    "        # Set the title for each subplot\n",
    "        axes[idx].set_title(f'Concept: {category}')\n",
    "\n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    # Save to PDF\n",
    "    plt.savefig(output_path, format=\"pdf\")\n",
    "    plt.show()\n",
    "\n",
    "# Get intervention categories in paper order\n",
    "intervention_categories = [\"loop_through\",\"parameter\",\"provide\",\"return\",\"skip\",\"string\",\n",
    "                           \"concatenate\",\"dictionary\",\"insert\",\"integer\",\"key\",\"list\",\n",
    "                           \"take\",\"typecast\"]\n",
    "\n",
    "plot_heatmap(llama3p1_8b_with_others_df, intervention_categories[:6], \"pass1_diff_llama3p1_8b_heatmap_1.pdf\")\n",
    "plot_heatmap(llama3p1_8b_with_others_df, intervention_categories[6:12], \"pass1_diff_llama3p1_8b_heatmap_2.pdf\")\n",
    "plot_heatmap(llama3p1_8b_with_others_df, intervention_categories[12:], \"pass1_diff_llama3p1_8b_heatmap_3.pdf\", nrows=1, ncols=2, figsize=(8.5, 11 / 3))\n",
    "\n",
    "plot_heatmap(llama3p1_70b_with_others_df, intervention_categories[:6], \"pass1_diff_llama3p1_70b_heatmap_1.pdf\")\n",
    "plot_heatmap(llama3p1_70b_with_others_df, intervention_categories[6:12], \"pass1_diff_llama3p1_70b_heatmap_2.pdf\")\n",
    "plot_heatmap(llama3p1_70b_with_others_df, intervention_categories[12:], \"pass1_diff_llama3p1_70b_heatmap_3.pdf\", nrows=1, ncols=2, figsize=(8.5, 11 / 3))\n",
    "\n",
    "plot_heatmap(gpt4o_mini_with_others_df, intervention_categories[:6], \"pass1_diff_gpt4o_mini_heatmap_1.pdf\")\n",
    "plot_heatmap(gpt4o_mini_with_others_df, intervention_categories[6:12], \"pass1_diff_gpt4o_mini_heatmap_2.pdf\")\n",
    "plot_heatmap(gpt4o_mini_with_others_df, intervention_categories[12:], \"pass1_diff_gpt4o_mini_heatmap_3.pdf\", nrows=1, ncols=2, figsize=(8.5, 11 / 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Mixed-Effect Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dump_csv_for_mixed_effects(df, filename):\n",
    "    output_df = df[[\"studenteval_id\", \"problem_x\", \"n_successes_x\", \"pass1_x\", \"intervention_category\", \"intervention\", \"original_word\", \"n_successes_y\", \"pass1_y\"]].copy()\n",
    "    output_df.rename(columns = {\n",
    "        \"studenteval_id\": \"prompt_id\",\n",
    "        \"problem_x\": \"problem\",\n",
    "        \"n_successes_y\": \"n_successes_original\",\n",
    "        \"pass1_y\": \"pass1_original\",\n",
    "        \"n_successes_x\": \"n_successes_intervened\",\n",
    "        \"pass1_x\": \"pass1_intervened\",\n",
    "    }, inplace=True)\n",
    "    output_df[\"model\"] = \"llama3p1_8b_base\"\n",
    "    output_df.head()\n",
    "    output_df.to_csv(filename, index=False)\n",
    "\n",
    "dump_csv_for_mixed_effects(llama3p1_8b_with_others_df, \"llama3p1_8b_base.csv\")\n",
    "dump_csv_for_mixed_effects(llama3p1_70b_with_others_df, \"llama3p1_70b_base.csv\")\n",
    "dump_csv_for_mixed_effects(gpt4o_mini_with_others_df, \"gpt4o_mini.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
