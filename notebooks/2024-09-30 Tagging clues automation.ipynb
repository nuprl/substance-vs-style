{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below loads YAML without the Graph stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IgnoreUnknownTagLoader(yaml.SafeLoader):\n",
    "    def ignore_unknown(self, suffix, node):\n",
    "        if isinstance(node, yaml.MappingNode):\n",
    "            return self.construct_mapping(node)\n",
    "        elif isinstance(node, yaml.SequenceNode):\n",
    "            return self.construct_sequence(node)\n",
    "        else:\n",
    "            return self.construct_scalar(node)\n",
    "\n",
    "IgnoreUnknownTagLoader.add_multi_constructor('', IgnoreUnknownTagLoader.ignore_unknown)\n",
    "\n",
    "with Path(\"../tagging_clues/tagging_graphs_sep27/laugh.yaml\").open() as f:\n",
    "    graph = yaml.load(f, Loader=IgnoreUnknownTagLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"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\"\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "CLIENT = openai.OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml(path: Path):\n",
    "    with path.open() as f:\n",
    "        return yaml.safe_load(f)\n",
    "    \n",
    "\n",
    "PROMPT_CONTEXT = read_yaml(Path(\"prompt.yaml\"))\n",
    "\n",
    "def format_edge(edge):\n",
    "    lines = [ ]\n",
    "    lines.append(\"The student started with this prompt:\\n\")\n",
    "    lines.append(\"```\")\n",
    "    lines.append(edge[\"prompt_from\"])\n",
    "    lines.append(\"```\\n\\nAnd turned it into the following prompt:\\n\\n```\")\n",
    "    lines.append(edge[\"prompt_to\"])\n",
    "    lines.append(\"```\\n\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def query(edge):\n",
    "    messages = [ *PROMPT_CONTEXT, {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": format_edge(edge)\n",
    "    } ]\n",
    "    response = CLIENT.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return (format_edge(edge), response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph[\"edges\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student started with this prompt:\n",
      "\n",
      "```\n",
      "def laugh(size):\n",
      "    \"\"\"\n",
      "    The function will repeat the word \"ha\" based on the size inputted. Each time the word \"ha\" is printed, the number of \"a\"s in the \"ha\" will start with its initial size, then decrease by one for each repetition.\n",
      "    \"\"\"\n",
      "    \n",
      "```\n",
      "\n",
      "And turned it into the following prompt:\n",
      "\n",
      "```\n",
      "def laugh(size):\n",
      "    \"\"\"\n",
      "    Based on the inputted number, will return a laugh size where the number of \"a\"'s starts with the initial size, then decreases by one for each additional laugh.\n",
      "    \"\"\"\n",
      "    \n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_edge(graph[\"edges\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added concepts:\n",
      "\n",
      "- None\n",
      "\n",
      "Reworded concepts:\n",
      "\n",
      "- 2: reverse order — The original prompt described a “decrease by one for each repetition” that implies the order of the output is sequentially diminishing. The revised prompt shifts the emphasis slightly to suggest the number of \"a\"s begins at an initial size and decreases with each laugh, suggesting a more direct relationship with the input for output (i.e., additional laughs).\n",
      "\n",
      "Removed concepts:\n",
      "\n",
      "- 4: space separation — The revised prompt does not explicitly mention the word \"repeated\" or specify the spacing of the laughs; it implies using \"laugh size,\" which could potentially signify a lack of space separation between instances.\n",
      "\n",
      "Unchanged concepts:\n",
      "\n",
      "- 1: prefix h — The \"ha\" structure remains present in both prompts.\n",
      "- 3: number of a-s is based on size — The concept remains that the number of 'a's starts with the initial size; this hasn't changed and is still reflected in both versions.\n",
      "- 5: down to 1 — The idea of decreasing the number of ‘a’s continues to be present regardless of the specific wording regarding “each repetition” or “additional laugh.”\n",
      "\n",
      "Summary:\n",
      "\n",
      "```\n",
      "- l2\n",
      "- d4\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(query(graph[\"edges\"][1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
