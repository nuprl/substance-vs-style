{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset,Original_Pass@1,Updated_Pass@1,NumProblems,Delta_Pass@1\n",
      "generations_two.of.each.firstlast.all.39b90b2_string_string,0.3333,0.2417,6,-0.0917\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import argparse\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import gzip\n",
    "from typing import Optional\n",
    "import sys\n",
    "\n",
    "\n",
    "def gunzip_json(path: Path) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Reads a .json.gz file, but produces None if any error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with gzip.open(path, \"rt\") as f:\n",
    "            data = json.load(f)\n",
    "            return data\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def gzip_json(path: Path, data: dict) -> None:\n",
    "    with gzip.open(path, \"wt\") as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "\n",
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)\n",
    "\n",
    "\n",
    "def estimator(n: int, c: int, k: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculates 1 - comb(n - c, k) / comb(n, k).\n",
    "    \"\"\"\n",
    "    if n - c < k:\n",
    "        return 1.0\n",
    "    return 1.0 - np.prod(1.0 - k / np.arange(n - c + 1, n + 1))\n",
    "\n",
    "import re\n",
    "#this checks change by directly comparing the prompt before and after the substitution\n",
    "#another way is to go back at the tagged prompts and see the tags\n",
    "def check_changed(data):\n",
    "    submitted_text = data['submitted_text'].strip().lstrip()\n",
    "    prompt = data['prompt']\n",
    "    match = re.search(r'\"\"\"\\s*(.*?)\\s*\"\"\"', prompt, re.DOTALL)\n",
    "    if match:\n",
    "        content = match.group(1).strip().lstrip()\n",
    "        return content != submitted_text\n",
    "    else:\n",
    "        raise ValueError(\"No content found between triple quotes.\")\n",
    "\n",
    "def check_success(data):\n",
    "    subset = data['subset']\n",
    "    success = 'success' in subset\n",
    "    return success\n",
    "    \n",
    "    \n",
    "def for_file(path):\n",
    "    data = gunzip_json(path)\n",
    "    if data is None:\n",
    "        return None\n",
    "    changed = check_changed(data)\n",
    "    success = check_success(data)\n",
    "        \n",
    "    n = len(data[\"results\"])\n",
    "    c = len([True for r in data[\"results\"] if r[\"status\"]\n",
    "            == \"OK\" and r[\"exit_code\"] == 0])\n",
    "    __index_level_0__ = data[\"__index_level_0__\"]\n",
    "\n",
    "    return {\n",
    "        \"__index_level_0__\":__index_level_0__,\n",
    "        \"changed\":changed,\n",
    "        \"success\":success,\n",
    "        \"pass@1\": estimator(n, c, 1),\n",
    "        \"pass@10\": estimator(n, c, 10),\n",
    "        \"pass@100\": estimator(n, c, 100),\n",
    "        \"n\": n,\n",
    "        \"c\": c,\n",
    "        \"temperature\": data[\"temperature\"] if \"temperature\" in data else 0.2\n",
    "    }\n",
    "\n",
    "    \n",
    "def for_file_orig(path):\n",
    "    data = gunzip_json(path)\n",
    "    if data is None:\n",
    "        return None\n",
    "    n = len(data[\"results\"])\n",
    "    c = len([True for r in data[\"results\"] if r[\"status\"]\n",
    "            == \"OK\" and r[\"exit_code\"] == 0])\n",
    "    __index_level_0__ = data[\"__index_level_0__\"]\n",
    "    return {\n",
    "        \"__index_level_0__\":__index_level_0__,\n",
    "        \"pass@1\": estimator(n, c, 1),\n",
    "        \"pass@10\": estimator(n, c, 10),\n",
    "        \"pass@100\": estimator(n, c, 100),\n",
    "        \"n\": n,\n",
    "        \"c\": c,\n",
    "        \"temperature\": data[\"temperature\"] if \"temperature\" in data else 0.2\n",
    "    }\n",
    "\n",
    "def main(orig_dir,d):\n",
    "    \n",
    "    orig_results = [for_file_orig(p) for p in itertools.chain(\n",
    "            Path(orig_dir).glob(\"*.results.json\"), Path(orig_dir).glob(\"*.results.json.gz\"))]\n",
    "    orig_results = [r for r in orig_results if r is not None]\n",
    "    print(\"Dataset,Original_Pass@1,Updated_Pass@1,NumProblems,Delta_Pass@1\")\n",
    "    name = d.split(\"/\")[-2] if d.split(\"/\")[-1] != \"\" else d.split(\"/\")[-3]\n",
    "    results = [for_file(p) for p in itertools.chain(\n",
    "        Path(d).glob(\"*.results.json\"), Path(d).glob(\"*.results.json.gz\"))]\n",
    "    changed_results = {r[\"__index_level_0__\"]:r for r in results if r[\"changed\"] and r[\"success\"]}\n",
    "    changed_results = list(changed_results.values())\n",
    "    changed_indices = [r[\"__index_level_0__\"] for r in changed_results]\n",
    "    filtered_orig_results_changed = [r for r in orig_results if r[\"__index_level_0__\"] in changed_indices]\n",
    "    num_problems_changed = len(changed_results)\n",
    "    assert len(filtered_orig_results_changed) == num_problems_changed\n",
    "    pass_1_original_changed = np.mean([r[\"pass@1\"] for r in filtered_orig_results_changed]) if filtered_orig_results_changed else float('nan')\n",
    "    pass_1_updated_changed = np.mean([r[\"pass@1\"] for r in changed_results]) if changed_results else float('nan')\n",
    "\n",
    "    delta_changed = pass_1_updated_changed - pass_1_original_changed\n",
    "    print(\n",
    "        f\"{name},{pass_1_original_changed:.4f},{pass_1_updated_changed:.4f},{num_problems_changed},{delta_changed:.4f}\")\n",
    "\n",
    "#if on boa: eg.with a prev generation still on boa\n",
    "main(\"/mnt/ssd/aryawu/studenteval_nlp/generation_experiments/generations_studenteval/multiple\",\"/mnt/ssd/aryawu/studenteval_nlp/generation_experiments/generations_two.of.each.firstlast.all.39b90b2_string_string/multiple\")\n",
    "#if on discovery:eg.\n",
    "# main(\"generation_experiments/70b_generations_studenteval/multiple\",\"generation_experiments/generations_all.prompts.full.label.d2c1570_concatenate_add/multiple\",\"add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset,target_orig,Original_Pass@1,Updated_Pass@1,NumProblems,Delta_Pass@1\n",
      "generations_two.of.each.firstlast.all.39b90b2_string_string,word,0.2000,0.1800,5,-0.0200\n",
      "generations_two.of.each.firstlast.all.39b90b2_string_string,phrase,nan,nan,0,nan\n",
      "generations_two.of.each.firstlast.all.39b90b2_string_string,string,0.0000,0.0500,1,0.0500\n",
      "generations_two.of.each.firstlast.all.39b90b2_string_string,character,nan,nan,0,nan\n",
      "generations_two.of.each.firstlast.all.39b90b2_string_string,set of characters,nan,nan,0,nan\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import argparse\n",
    "import datasets\n",
    "from pathlib import Path\n",
    "import json\n",
    "import gzip\n",
    "from typing import Optional\n",
    "import sys\n",
    "\n",
    "subst_to_run = {\n",
    "    \"string\": [\"word\",\"phrase\",\"string\",\"character\",\"set of characters\"],\n",
    "    \"list\":[\"brackets\",\"set of brackets\",\"set\",\"list\",\"array list\",\"array\"],\n",
    "    \"dictionary\":[\"map\",\"dictionary\"],\n",
    "    \"integer\": [\"integer\",\"whole number\",\"int\"],\n",
    "    \"return\": [\"return\",\"output\",\"print\",\"produce\",\"display\"],\n",
    "    \"parameter\": [\"parameter\",\"argument\",\"value provided\",\"input\"],\n",
    "    \"take\": [\"take\",\"bring in\",\"accept\",\"get\",\"input\"],\n",
    "    \"provide\": [\"provide\",\"enter\",\"input\"],\n",
    "    \"concatenate\": [\"concatenate\",\"combine\",\"splice\",\"add\"],\n",
    "    \"insert\": [\"insert\",\"add\",\"append\",\"attach\"],\n",
    "    \"loop through\": [\"go through\",\"run through\",\"iterate through\",\"loop through\",\"run a for loop through\",\"look through\",\"execute a for loop with\"],\n",
    "    \"skip\": [\"skip\",\"avoid\",\"neglect\",\"ignore\",\"remove\"],\n",
    "    \"typecast\": [\"typecast\",\"type cast\",\"cast\",\"convert\",\"change\"],\n",
    "    \"key\": [\"key\",\"item\",\"entry\",\"attribute\",\"part\",\"element\",\"variable\"],\n",
    "}\n",
    "\n",
    "WORDS_V = {\n",
    "    \"word\":[\"word\",\"words\"],\n",
    "    \"phrase\":[\"phrase\",\"phrases\"],\n",
    "    \"string\":[\"string\",\"strings\"],\n",
    "    \"character\":[\"character\",\"characters\"],\n",
    "    \"set of characters\":[\"set of characters\",\"sets of characters\"],\n",
    "    \"brackets\":[\"brackets\"],\n",
    "    \"set of brackets\":[\"set of brackets\",\"sets of brackets\"],\n",
    "    \"set\":[\"set\",\"sets\"],\n",
    "    \"list\":[\"list\",\"lists\"],\n",
    "    \"array\":[\"array\",\"arrays\"],\n",
    "    \"array list\":[\"array list\",\"array lists\"],\n",
    "    \"map\":[\"map\",\"maps\"],\n",
    "    \"dictionary\":[\"dictionary\",\"dictionaries\"],\n",
    "    \"integer\":[\"integer\",\"integers\"],\n",
    "    \"whole number\":[\"whole number\",\"whole numbers\"],\n",
    "    \"int\":[\"int\",\"ints\"],\n",
    "    \"output\":[\"output\",\"outputs\",\"outputted\",\"outputting\"],\n",
    "    \"return\":[\"return\",\"returns\",\"returned\",\"returning\"],\n",
    "    \"print\":[\"print\",\"prints\",\"printed\",\"printing\"],\n",
    "    \"produce\":[\"produce\",\"produces\",\"produced\",\"producing\"],\n",
    "    \"display\":[\"display\",\"displays\",\"displayed\",\"displaying\"],\n",
    "    \"parameter\":[\"parameter\",\"parameters\"],\n",
    "    \"argument\":[\"argument\",\"arguments\"],\n",
    "    \"value provided\":[\"value provided\",\"values provided\"],\n",
    "    \"input\":[\"input\",\"inputs\",\"inputted\"],\n",
    "    \"take\":[\"take\",\"takes\"],\n",
    "    \"bring in\":[\"bring in\",\"brings in\"],\n",
    "    \"accept\":[\"accept\",\"accepts\"],\n",
    "    \"get\":[\"get\",\"gets\"],\n",
    "    \"provide\":[\"provide\",\"provides\",\"provided\"],\n",
    "    \"enter\":[\"enter\",\"enters\",\"entered\"],\n",
    "    \"combine\":[\"combine\",\"combines\",\"combined\",\"combining\"],\n",
    "    \"splice\":[\"splice\",\"splices\",\"spliced\",\"splicing\"],\n",
    "    \"concatenate\":[\"concatenate\",\"concatenates\",\"concatenated\",\"concatenating\"],\n",
    "    \"add\":[\"add\",\"adds\",\"added\",\"adding\"],\n",
    "    \"insert\":[\"insert\",\"inserts\",\"inserted\",\"inserting\"],\n",
    "    \"attach\":[\"attach\",\"attaches\",\"attached\",\"attaching\"],\n",
    "    \"append\":[\"append\",\"appends\",\"appended\",\"appending\"],\n",
    "    \"go through\":[\"go through\",\"goes through\"],\n",
    "    \"run through\":[\"run through\",\"runs through\"],\n",
    "    \"iterate through\":[\"iterate through\",\"iterates through\"],\n",
    "    \"loop through\":[\"loop through\",\"loops through\"],\n",
    "    \"run a for loop through\":[\"run a for loop through\",\"runs a for loop through\"],\n",
    "    \"look through\":[\"look through\",\"looks through\"],\n",
    "    \"execute a for loop with\":[\"execute a for loop with\",\"executes a for loop with\"],\n",
    "    \"skip\":[\"skip\",\"skips\",\"skipped\",\"skipping\"],\n",
    "    \"avoid\":[\"avoid\",\"avoids\",\"avoided\",\"avoiding\"],\n",
    "    \"neglect\":[\"neglect\",\"neglects\",\"neglected\",\"neglecting\"],\n",
    "    \"ignore\":[\"ignore\",\"ignores\",\"ignored\",\"ignoring\"],\n",
    "    \"remove\":[\"remove\",\"removes\",\"removed\",\"removing\"],\n",
    "    \"convert\":[\"convert\",\"converts\",\"converted\",\"converting\"],\n",
    "    \"change\":[\"change\",\"changes\",\"changed\",\"changing\"],\n",
    "    \"typecast\":[\"typecast\",\"typecasts\",\"typecasted\",\"typecasting\"],\n",
    "    \"type cast\":[\"type cast\",\"type casts\",\"type casted\",\"type casting\"],\n",
    "    \"cast\":[\"cast\",\"casts\",\"casted\",\"casting\"],\n",
    "    \"key\":[\"key\",\"keys\"],\n",
    "    \"item\":[\"item\",\"items\"],\n",
    "    \"entry\":[\"entry\",\"entries\"],\n",
    "    \"attribute\":[\"attribute\",\"attributes\"],\n",
    "    \"part\":[\"part\",\"parts\"],\n",
    "    \"element\":[\"element\",\"elements\"],\n",
    "    \"variable\":[\"variable\",\"variables\"],\n",
    "}\n",
    "\n",
    "# Same pairs exist in WORDS_V. Separating them to gaurd against wrong --category input.\n",
    "CATEGORIES_V = {\n",
    "    \"string\": [\"string\", \"strings\"],\n",
    "    \"list\": [\"list\", \"lists\"],\n",
    "    \"dictionary\": [\"dictionary\", \"dictionaries\"],\n",
    "    \"integer\": [\"integer\", \"integers\"],\n",
    "    \"return\": [\"return\", \"returns\", \"returned\", \"returning\"],\n",
    "    \"parameter\": [\"parameter\", \"parameters\"],\n",
    "    \"take\": [\"take\", \"takes\"],\n",
    "    \"provide\": [\"provide\", \"provides\", \"provided\"],\n",
    "    \"concatenate\": [\"concatenate\", \"concatenates\", \"concatenated\", \"concatenating\"],\n",
    "    \"insert\": [\"insert\", \"inserts\", \"inserted\", \"inserting\"],\n",
    "    \"loop through\": [\"loop through\", \"loops through\"],\n",
    "    \"skip\": [\"skip\", \"skips\", \"skipped\", \"skipping\"],\n",
    "    \"typecast\": [\"typecast\", \"typecasts\", \"typecasted\", \"typecasting\"],\n",
    "    \"key\": [\"key\", \"keys\"]\n",
    "}\n",
    "\n",
    "\n",
    "def gunzip_json(path: Path) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Reads a .json.gz file, but produces None if any error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with gzip.open(path, \"rt\") as f:\n",
    "            data = json.load(f)\n",
    "            return data\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def gzip_json(path: Path, data: dict) -> None:\n",
    "    with gzip.open(path, \"wt\") as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "\n",
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)\n",
    "\n",
    "\n",
    "def estimator(n: int, c: int, k: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculates 1 - comb(n - c, k) / comb(n, k).\n",
    "    \"\"\"\n",
    "    if n - c < k:\n",
    "        return 1.0\n",
    "    return 1.0 - np.prod(1.0 - k / np.arange(n - c + 1, n + 1))\n",
    "\n",
    "import re\n",
    "#this checks change by directly comparing the prompt before and after the substitution\n",
    "def check_changed(data):\n",
    "    submitted_text = data['submitted_text'].strip().lstrip()\n",
    "    prompt = data['prompt']\n",
    "    match = re.search(r'\"\"\"\\s*(.*?)\\s*\"\"\"', prompt, re.DOTALL)\n",
    "    if match:\n",
    "        content = match.group(1).strip().lstrip()\n",
    "        return content != submitted_text\n",
    "    else:\n",
    "        raise ValueError(\"No content found between triple quotes.\")\n",
    "\n",
    "#if we want to know about the specific original words\n",
    "def check_original_word(data,all_tagged_prompts,category,target_original):\n",
    "    tagged_prompt = [item for item in all_tagged_prompts if item['__index_level_0__'] == data['__index_level_0__']]\n",
    "    assert len(tagged_prompt)==1\n",
    "    tagged_prompt = tagged_prompt[0]\n",
    "    pattern = re.compile(r\"\\$([\\w\\s]+):([\\w\\s]+)\\$\")\n",
    "    is_orig_target = False\n",
    "    for match in pattern.finditer(tagged_prompt['prompt']):\n",
    "        # Extract CATEGORY\n",
    "        this_category = match.group(1)\n",
    "        this_original = match.group(2)\n",
    "        if this_category in CATEGORIES_V[category]:\n",
    "            if this_original in WORDS_V[target_original]:\n",
    "                is_orig_target = True\n",
    "    # if is_orig_target:\n",
    "    #     print(\"found original word\",target_original,\"tagged in\",tagged_prompt['prompt'])\n",
    "    return is_orig_target  \n",
    "        \n",
    "\n",
    "def check_success(data):\n",
    "    subset = data['subset']\n",
    "    success = 'success' in subset\n",
    "    return success\n",
    "    \n",
    "    \n",
    "def for_file(path,all_tagged_prompts,category,target_original):\n",
    "    data = gunzip_json(path)\n",
    "    if data is None:\n",
    "        return None\n",
    "    origword = check_original_word(data,all_tagged_prompts,category,target_original)\n",
    "    changed = check_changed(data)\n",
    "    success = check_success(data)\n",
    "        \n",
    "    n = len(data[\"results\"])\n",
    "    c = len([True for r in data[\"results\"] if r[\"status\"]\n",
    "            == \"OK\" and r[\"exit_code\"] == 0])\n",
    "    __index_level_0__ = data[\"__index_level_0__\"]\n",
    "\n",
    "    return {\n",
    "        \"__index_level_0__\":__index_level_0__,\n",
    "        \"changed\":changed,\n",
    "        \"success\":success,\n",
    "        \"origword\":origword,\n",
    "        \"pass@1\": estimator(n, c, 1),\n",
    "        \"pass@10\": estimator(n, c, 10),\n",
    "        \"pass@100\": estimator(n, c, 100),\n",
    "        \"n\": n,\n",
    "        \"c\": c,\n",
    "        \"temperature\": data[\"temperature\"] if \"temperature\" in data else 0.2\n",
    "    }\n",
    "\n",
    "    \n",
    "def for_file_orig(path):\n",
    "    data = gunzip_json(path)\n",
    "    if data is None:\n",
    "        return None\n",
    "    n = len(data[\"results\"])\n",
    "    c = len([True for r in data[\"results\"] if r[\"status\"]\n",
    "            == \"OK\" and r[\"exit_code\"] == 0])\n",
    "    __index_level_0__ = data[\"__index_level_0__\"]\n",
    "    return {\n",
    "        \"__index_level_0__\":__index_level_0__,\n",
    "        \"pass@1\": estimator(n, c, 1),\n",
    "        \"pass@10\": estimator(n, c, 10),\n",
    "        \"pass@100\": estimator(n, c, 100),\n",
    "        \"n\": n,\n",
    "        \"c\": c,\n",
    "        \"temperature\": data[\"temperature\"] if \"temperature\" in data else 0.2\n",
    "    }\n",
    "\n",
    "def main(orig_dir,d):\n",
    "    all_tagged_prompts = datasets.load_dataset(\"nuprl-staging/studenteval_tagged_prompts\",split = \"all.prompts.full.label.d2c1570\")\n",
    "    print(\"Dataset,target_orig,Original_Pass@1,Updated_Pass@1,NumProblems,Delta_Pass@1\")\n",
    "    orig_results = [for_file_orig(p) for p in itertools.chain(\n",
    "            Path(orig_dir).glob(\"*.results.json\"), Path(orig_dir).glob(\"*.results.json.gz\"))]\n",
    "    orig_results = [r for r in orig_results if r is not None]\n",
    "    name = d.split(\"/\")[-2] if d.split(\"/\")[-1] != \"\" else d.split(\"/\")[-3]\n",
    "    suffix = name.split(\".\")[-1]\n",
    "    if \"loop_through\" in suffix:\n",
    "        category = \"loop through\"\n",
    "    else:\n",
    "        category = suffix.split(\"_\")[1]\n",
    "    all_target_original = subst_to_run[category]\n",
    "    for target_original in all_target_original:\n",
    "        # print(\"for category\",category,\"replace\",target_original,\"with\",replacement)\n",
    "        results = [for_file(p,all_tagged_prompts,category,target_original) for p in itertools.chain(\n",
    "            Path(d).glob(\"*.results.json\"), Path(d).glob(\"*.results.json.gz\"))]\n",
    "        changed_results = {r[\"__index_level_0__\"]:r for r in results if r[\"changed\"] and r[\"success\"] and r['origword']}\n",
    "        # print(len(changed_results))\n",
    "        changed_results = list(changed_results.values())\n",
    "        changed_indices = [r[\"__index_level_0__\"] for r in changed_results]\n",
    "        filtered_orig_results_changed = [r for r in orig_results if r[\"__index_level_0__\"] in changed_indices]\n",
    "        num_problems_changed = len(changed_results)\n",
    "        assert len(filtered_orig_results_changed) == num_problems_changed\n",
    "        pass_1_original_changed = np.mean([r[\"pass@1\"] for r in filtered_orig_results_changed]) if filtered_orig_results_changed else float('nan')\n",
    "        pass_1_updated_changed = np.mean([r[\"pass@1\"] for r in changed_results]) if changed_results else float('nan')\n",
    "\n",
    "        delta_changed = pass_1_updated_changed - pass_1_original_changed\n",
    "        print(\n",
    "            f\"{name},{target_original},{pass_1_original_changed:.4f},{pass_1_updated_changed:.4f},{num_problems_changed},{delta_changed:.4f}\")\n",
    "\n",
    "#if on boa: eg.\n",
    "main(\"/mnt/ssd/aryawu/studenteval_nlp/generation_experiments/generations_studenteval/multiple\",\"/mnt/ssd/aryawu/studenteval_nlp/generation_experiments/generations_two.of.each.firstlast.all.39b90b2_string_string/multiple\")\n",
    "#if on discovery: eg.\n",
    "# main(\"generation_experiments/70b_generations_studenteval/multiple\",\"generation_experiments/generations_all.prompts.full.label.d2c1570_concatenate_add/multiple\",\"add\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
